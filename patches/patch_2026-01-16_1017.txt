Great — then let’s make the next commit explicitly about practical ingestion without locking ourselves into “PDF is the format” or “API is the format.”

What this commit will deliver

A canonical ingestion contract (internal IR) so any source can be adapted:

DocumentIR for “big text” (PDF→text output, markdown, etc.)

EntityIR for “structured things” (API JSON)

A first real adapter: D&D 5e API ingest (spells + monsters to start)

DB support to store:

raw entity JSON

a “rendered text” chunk per entity (so retrieval/citations work the same way as documents)

This keeps your pipeline future-proof: PDF text goes through DocumentIR; API data goes through EntityIR.

Commit plan: “Add Entity IR + dnd5eapi ingest adapter”
1) DB migration v2 (entities + link chunks to entities)

Update ddai_store:

crates/ddai_store/src/lib.rs changes

bump SCHEMA_VERSION to 2

add a safe migration that:

adds chunks.entity_id column if missing

creates entities table

Here’s the patch content (copy/paste friendly):

// change
pub const SCHEMA_VERSION: i64 = 2;


Add helper:

fn column_exists(conn: &Connection, table: &str, column: &str) -> Result<bool> {
    let mut stmt = conn.prepare(&format!("PRAGMA table_info({})", table))?;
    let rows = stmt.query_map([], |r| r.get::<_, String>(1))?;
    for r in rows {
        if r? == column {
            return Ok(true);
        }
    }
    Ok(false)
}


In migrate() add v2:

for next in (current + 1)..=SCHEMA_VERSION {
    match next {
        1 => self.migration_v1()?,
        2 => self.migration_v2()?,
        _ => anyhow::bail!("unknown migration version: {next}"),
    }
    ...
}


Add migration_v2():

fn migration_v2(&self) -> Result<()> {
    if !column_exists(&self.conn, "chunks", "entity_id")? {
        self.conn.execute("ALTER TABLE chunks ADD COLUMN entity_id INTEGER", [])?;
    }

    self.conn.execute_batch(
        r#"
        CREATE TABLE IF NOT EXISTS entities (
          id           INTEGER PRIMARY KEY AUTOINCREMENT,
          kind         TEXT NOT NULL,
          api_index    TEXT NOT NULL,
          name         TEXT NOT NULL,
          source       TEXT NOT NULL,
          original_ref TEXT,
          json         TEXT NOT NULL,
          created_at   INTEGER NOT NULL,
          UNIQUE(kind, api_index)
        );

        CREATE INDEX IF NOT EXISTS idx_entities_kind ON entities(kind);
        CREATE INDEX IF NOT EXISTS idx_chunks_entity_id ON chunks(entity_id);
        "#,
    )?;

    Ok(())
}


Now update insert_chunk() to optionally set entity_id:

pub fn insert_chunk(
    &self,
    document_id: i64,
    chunk_index: i64,
    content: &str,
    token_count: Option<i64>,
    sha256: &str,
    entity_id: Option<i64>,
) -> Result<i64> {
    let now = unix_ms();
    self.conn.execute(
        r#"
        INSERT INTO chunks(document_id, chunk_index, content, token_count, sha256, created_at, entity_id)
        VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7)
        "#,
        rusqlite::params![document_id, chunk_index, content, token_count, sha256, now, entity_id],
    )?;
    Ok(self.conn.last_insert_rowid())
}


Add insert_entity():

pub fn upsert_entity(
    &self,
    kind: &str,
    api_index: &str,
    name: &str,
    source: &str,
    original_ref: Option<&str>,
    json: &str,
) -> Result<i64> {
    let now = unix_ms();
    self.conn.execute(
        r#"
        INSERT INTO entities(kind, api_index, name, source, original_ref, json, created_at)
        VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7)
        ON CONFLICT(kind, api_index) DO UPDATE SET
          name=excluded.name,
          source=excluded.source,
          original_ref=excluded.original_ref,
          json=excluded.json
        "#,
        rusqlite::params![kind, api_index, name, source, original_ref, json, now],
    )?;

    let id: i64 = self.conn.query_row(
        "SELECT id FROM entities WHERE kind=?1 AND api_index=?2",
        rusqlite::params![kind, api_index],
        |r| r.get(0),
    )?;
    Ok(id)
}


This gives you “source of truth JSON” and chunk text for RAG.

2) Add ingestion IR + dnd5eapi adapter
crates/ddai_ingest/Cargo.toml

Add:

anyhow = "1"
sha2 = "0.10"
hex = "0.4"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
reqwest = { version = "0.12", default-features = false, features = ["blocking", "json", "rustls-tls"] }
ddai_store = { path = "../ddai_store" }

crates/ddai_ingest/src/lib.rs

Keep your file ingest, but update the insert_chunk(...) call signature to pass entity_id: None.

Then add a new module:

pub mod dnd5eapi;

crates/ddai_ingest/src/dnd5eapi.rs

This is a minimal, reliable adapter: list endpoint → fetch each item → store entity JSON → render to markdown → store chunk with entity_id.

use anyhow::{Context, Result};
use ddai_store::Store;
use serde::Deserialize;
use serde_json::Value;

use sha2::{Digest, Sha256};

#[derive(Debug, Deserialize)]
struct ApiList {
    results: Vec<ApiRef>,
}

#[derive(Debug, Deserialize)]
struct ApiRef {
    index: String,
    name: String,
    url: String,
}

pub struct Dnd5eApiOptions<'a> {
    pub base_url: &'a str,   // e.g. https://www.dnd5eapi.co
    pub source: &'a str,     // "dnd5eapi.co (SRD mirror)" or similar
    pub limit: Option<usize>,
}

pub fn ingest_spells_and_monsters(store: &Store, opts: Dnd5eApiOptions<'_>) -> Result<()> {
    ingest_kind(store, opts, "spells")?;
    ingest_kind(store, opts, "monsters")?;
    Ok(())
}

fn ingest_kind(store: &Store, opts: Dnd5eApiOptions<'_>, kind: &str) -> Result<()> {
    let client = reqwest::blocking::Client::new();

    let list_url = format!("{}/api/{}", opts.base_url.trim_end_matches('/'), kind);
    let list: ApiList = client
        .get(&list_url)
        .send()
        .with_context(|| format!("GET {list_url}"))?
        .error_for_status()
        .with_context(|| format!("HTTP error {list_url}"))?
        .json()
        .with_context(|| format!("parse json {list_url}"))?;

    let title = format!("DND5EAPI: {}", kind);
    let doc_id = store.insert_document(opts.source, Some(&title), None, None)?;

    let mut count = 0usize;
    for (i, r) in list.results.iter().enumerate() {
        if let Some(limit) = opts.limit {
            if i >= limit {
                break;
            }
        }

        let item_url = format!("{}/{}", opts.base_url.trim_end_matches('/'), r.url.trim_start_matches('/'));
        let v: Value = client
            .get(&item_url)
            .send()
            .with_context(|| format!("GET {item_url}"))?
            .error_for_status()
            .with_context(|| format!("HTTP error {item_url}"))?
            .json()
            .with_context(|| format!("parse json {item_url}"))?;

        let api_index = v.get("index").and_then(|x| x.as_str()).unwrap_or(&r.index);
        let name = v.get("name").and_then(|x| x.as_str()).unwrap_or(&r.name);

        let json = serde_json::to_string(&v)?;
        let entity_id = store.upsert_entity(kind, api_index, name, opts.source, Some(&item_url), &json)?;

        let rendered = render_entity(kind, &v);
        let sha = sha256_hex(&rendered);
        let token_est = estimate_tokens(&rendered);

        store.insert_chunk(doc_id, i as i64, &rendered, Some(token_est), &sha, Some(entity_id))?;

        count += 1;
        if count % 25 == 0 {
            println!("Ingested {count} {kind}...");
        }
    }

    println!("Ingest complete: {count} {kind} into document id={doc_id}");
    Ok(())
}

fn render_entity(kind: &str, v: &Value) -> String {
    match kind {
        "spells" => render_spell(v),
        "monsters" => render_monster(v),
        _ => format!("# {}\n\n{}", kind, v),
    }
}

fn render_spell(v: &Value) -> String {
    let name = s(v, "name");
    let level = v.get("level").and_then(|x| x.as_i64()).map(|n| n.to_string()).unwrap_or("-".into());
    let school = v.get("school").and_then(|x| x.get("name")).and_then(|x| x.as_str()).unwrap_or("-");
    let casting_time = s(v, "casting_time");
    let range = s(v, "range");
    let duration = s(v, "duration");
    let components = v.get("components").and_then(|x| x.as_array())
        .map(|a| a.iter().filter_map(|i| i.as_str()).collect::<Vec<_>>().join(", "))
        .unwrap_or("-".into());

    let desc = v.get("desc").and_then(|x| x.as_array())
        .map(|a| a.iter().filter_map(|i| i.as_str()).collect::<Vec<_>>().join("\n"))
        .unwrap_or_default();

    let higher = v.get("higher_level").and_then(|x| x.as_array())
        .map(|a| a.iter().filter_map(|i| i.as_str()).collect::<Vec<_>>().join("\n"))
        .unwrap_or_default();

    format!(
        "# Spell: {name}\n\n- Level: {level}\n- School: {school}\n- Casting Time: {casting_time}\n- Range: {range}\n- Components: {components}\n- Duration: {duration}\n\n## Description\n{desc}\n\n## Higher Level\n{higher}\n"
    )
}

fn render_monster(v: &Value) -> String {
    let name = s(v, "name");
    let size = s(v, "size");
    let mtype = v.get("type").and_then(|x| x.as_str()).unwrap_or("-");
    let alignment = s(v, "alignment");
    let ac = v.get("armor_class").and_then(|x| x.as_array()).and_then(|a| a.get(0))
        .and_then(|x| x.get("value").or(Some(x))).and_then(|x| x.as_i64()).map(|n| n.to_string()).unwrap_or("-".into());
    let hp = v.get("hit_points").and_then(|x| x.as_i64()).map(|n| n.to_string()).unwrap_or("-".into());
    let cr = v.get("challenge_rating").and_then(|x| x.as_f64()).map(|n| n.to_string()).unwrap_or("-".into());

    let str_ = n(v, "strength");
    let dex = n(v, "dexterity");
    let con = n(v, "constitution");
    let int_ = n(v, "intelligence");
    let wis = n(v, "wisdom");
    let cha = n(v, "charisma");

    let actions = v.get("actions").and_then(|x| x.as_array())
        .map(|a| {
            a.iter().map(|act| {
                let an = act.get("name").and_then(|x| x.as_str()).unwrap_or("-");
                let ad = act.get("desc").and_then(|x| x.as_str()).unwrap_or("");
                format!("- **{an}:** {ad}")
            }).collect::<Vec<_>>().join("\n")
        }).unwrap_or_default();

    format!(
        "# Monster: {name}\n\n- Size: {size}\n- Type: {mtype}\n- Alignment: {alignment}\n- AC: {ac}\n- HP: {hp}\n- CR: {cr}\n\n## Ability Scores\nSTR {str_} | DEX {dex} | CON {con} | INT {int_} | WIS {wis} | CHA {cha}\n\n## Actions\n{actions}\n"
    )
}

fn s(v: &Value, key: &str) -> String {
    v.get(key).and_then(|x| x.as_str()).unwrap_or("-").to_string()
}
fn n(v: &Value, key: &str) -> String {
    v.get(key).and_then(|x| x.as_i64()).map(|n| n.to_string()).unwrap_or("-".into())
}

fn sha256_hex(s: &str) -> String {
    let mut hasher = Sha256::new();
    hasher.update(s.as_bytes());
    hex::encode(hasher.finalize())
}
fn estimate_tokens(s: &str) -> i64 {
    let chars = s.chars().count() as i64;
    (chars / 4).max(1)
}

3) CLI command: ingest-dnd5eapi

In ddai_cli, add a subcommand:

ddai ingest-dnd5eapi --base-url https://www.dnd5eapi.co --limit 50 --source "dnd5eapi.co (SRD mirror)"

You’ll need to:

add dependency: ddai_ingest = { path = "../ddai_ingest" } (you already have)

add the command handler calling ddai_ingest::dnd5eapi::ingest_spells_and_monsters(...)

What to run after the commit
cargo run -p ddai_cli -- init-db
cargo run -p ddai_cli -- ingest-dnd5eapi --base-url https://www.dnd5eapi.co --limit 25 --source "dnd5eapi.co (SRD mirror)"
cargo run -p ddai_cli -- list-docs


At that point, your DB contains:

documents for spells and monsters

one chunk per spell/monster

raw JSON stored in entities